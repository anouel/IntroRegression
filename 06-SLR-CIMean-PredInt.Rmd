# Inference and Prediction for the Mean Response in SLR {#slrCIMean}

<!--- For HTML Only --->
`r if (!knitr:::is_latex_output()) '
$\\newcommand{\\E}{\\mathrm{E}}$
$\\newcommand{\\Var}{\\mathrm{Var}}$
$\\newcommand{\\bmx}{\\mathbf{x}}$
$\\newcommand{\\bmX}{\\mathbf{X}}$
'`

```{r include=FALSE}
library(tidyverse)
library(palmerpenguins)
library(broom)
```

## Estimating Mean & Predicting Observations

### Estimation or Prediction?

In Section \@ref(interpretslrrmean) we saw that the values along the regression line can be interpeted as the mean outcome for a given value of the predictor variable. Formally, we can write the **estimated mean** of $Y$ when $x$ equals some value $x_0$ as:

\begin{equation}
\hat\mu_{Y|x_0} = \hat\beta_0 + \hat\beta_1x_0
(\#eq:slrmuhat)
\end{equation}

The points along the line also provide the best *prediction* of the value of $Y$ for an observation with $x=x_0$. We write the **prediction for a new observation** of $Y$ when $x$ equals some value $x_0$ as:

\begin{equation}
\hat y_0 = \hat\beta_0 + \hat\beta_1x_0
(\#eq:slryhat)
\end{equation}

Although very similar, there an important distinction between the questions


1. What is the mean value of $Y$ when $x=x_0$?
2. What is the value of a new observation with $x=x_0$?

The point estimate for these questions is the same, but the corresponding uncertainty is different.
Question 1 is answered by $\hat\mu_{Y|x_0}$ and has a corresponding confidence interval. Question 2 is answered by $\hat y_0$ and has a corresponding prediction interval.


### Computing $\hat\mu_{Y|x_0}$ and $\hat{y}_0$

The point estimates $\hat\mu_{Y|x_0}$  and $\hat{y}_0$ can be computed by directly plugging in the point estimates to \@ref(eq:slrmuhat) or \@ref(eq:slryhat). 

```{example penguin-lm-prediction}
In Example \@ref(exm:penguin-lm-stepped), we saw the fitted regression line for mean peguin body mass ($y$) as a function of flipper length ($x$) was:
$$\hat{y}  = -5780.83 + 49.69x$$
Using this model, what is the mean body mass for a penguin with flipper length of 200mm?  
```
```{solution} 
(Version 1) We can compute these directly from the model objects:
```
```{r eval=TRUE, echo=TRUE, size="footnotesize"}
penguin_lm <- lm(body_mass_g ~ flipper_length_mm,
   data=penguins)
```

```{r eval=TRUE, echo=TRUE, size="footnotesize"}
x0 <- 200
muhat <- coef(penguin_lm)[1] + coef(penguin_lm)[2]*x0
muhat
```  
From this, we obtain the estimated mean as 4,156 grams.


But rather than compute this value using addition and multiplication, we can use the `predict()` function in R, which will compute these values for us based on a fitted `lm` object. The necessary arguments for making predictions are:

* `object=`, the `lm` for the model you want to make predictions for
* `newdata=`, a data frame containing the *named* variables with the values for prediction


```{solution} 
(Version 2 for Example \@ref(exm:penguin-lm-prediction).) Rather than do the arithmetic by hand, we can use the `predict()` function. We create a data frame called `preddata` that contains the information for prediction, and then pass it to `predict()`.
```
```{r eval=TRUE, echo=TRUE, size="footnotesize"}
penguin_lm <- lm(body_mass_g ~ flipper_length_mm,
   data=penguins)
preddata <- data.frame(flipper_length_mm=200)
predict(penguin_lm,
        newdata=preddata)
```  
We again obtain the estimated mean as 4,156 grams. 


In addition to being less likely to lead to typos, using the `predict()` command is easily scalable to multiple values.

```{example peng-lm-multimean}
For the same model as Example \@ref(exm:penguin-lm-prediction), what is the predicted mean body mass for penguins with flipper lengths of 150mm, 200mm, 225mm, and 250mm?
```
```{solution}
We can create a data frame with muliple values and then make predictions using that data frame:
```{r}
preddata2 <- data.frame(flipper_length_mm=c(150, 200, 225, 250))
predict(penguin_lm,
        newdata=preddata2)
```



## Inference for the mean ($\mu_{Y|x_0}$)

### CIs and Testing

Confidence intervals for $\mu_{Y | x_0}$ can be constructed in the same way as for the $\beta$'s:

\begin{equation}
\left(\hat\mu_{y|x_0} - t_{\alpha/2}\widehat{se}(\hat\mu_{y|x_0}), \hat\mu_{y|x_0} + t_{\alpha/2}\widehat{se}(\hat\mu_{y|x_0})\right).
(\#eq:meanCI)
\end{equation}

Hypothesis testing for the mean response is much less common, since inference is usually done on the regression slope ($\beta_1$) or the model overall (Section \@ref(slrFtest)). But if needed, it is also conducted in a manner analogous to the $\beta$'s:

$$H_0: \mu_{y|x_0} = \mu^0_{y|x_0} \qquad \text{vs.} \qquad H_A: \mu_{y|x_0} \ne \mu^0_{y|x_0}$$

\begin{equation}
t = \frac{\hat\mu_{y|x_0} - \mu^0_{y|x_0}}{\widehat{se}(\hat\mu_{y|x_0})}
(\#eq:meantstat)
\end{equation}



### Variance of $\hat\mu_{y|x_0}$

Computing either the confidence interval \@ref(eq:meanCI) or the test statistic \@ref(eq:meantstat) requires computing the standard erorr $\widehat{se}(\hat\mu_{y|x_0})$.


We can compute the variance of $\hat\mu_{y|x_0}$ as follows:

\begin{align}
\Var(\hat\mu_{y|x_0}) &= \Var\left(\hat\beta_0 + \hat\beta_1 x_0 \right)\\
& = \Var\left(\overline{y} - \hat\beta_1\overline{x} + \hat\beta_1 x_0 \right) (\#eq:varslrline2)\\
& = \Var\left(\overline{y} + \hat\beta_1(x_0 - \overline{x} )\right)\\
& = \Var\left(\overline{y}\right)  + \Var\left(\hat\beta_1(x_0 - \overline{x}) \right)\notag\\
& = \frac{\sigma^2}{n} + (x_0 - \overline{x})^2\Var\left(\hat\beta_1\right)\notag\\
& =  \frac{\sigma^2}{n}  + (x_0 - \overline{x})^2\frac{\sigma^2}{S_{xx}}\notag\\
& =  \sigma^2\left(\frac{1}{n}  + \frac{(x_0 - \overline{x})^2}{S_{xx}}\right) (\#eq:varslrmean)
\end{align}

It is important to note that $\Var\left(\hat\beta_0 + \hat\beta_1 x_0 \right) \ne \Var(\hat\beta_0) + \Var(\hat\beta_1x_0)$ since the estimators $\hat\beta_0$ and $\hat\beta_1$ are correlated. To obtain \@ref(eq:varslrline2), we have substituted in $\hat\beta_0 = \overline{y} - \hat\beta_1\overline{x}$ (recall equation \@ref(eq:hatbeta0)).



The variance \@ref(eq:varslrmean) changes as a function of $x$ and is minimized when $x_0 = \overline{x}$. This corresponds with what our intuition might tell us: that there is the least uncertainty near the center of the data.


### Computing the CI for Mean Response

#### "By Hand"

Using equation \@ref(eq:varslrmean), we can directly compute $\widehat{se}(\hat\mu_{y|x_0})$ and derive a confidence interval.

```{r eval=TRUE, echo=TRUE, size="footnotesize"}
# Be careful with missing values here
xbar <- mean(penguin_lm$model$flipper_length_mm) 
Sxx <- sum((penguin_lm$model$flipper_length_mm - xbar)^2)
n <- nobs(penguin_lm)
seMuHat <- sqrt(summary(penguin_lm)$sigma^2 * ((x0-xbar)^2/Sxx + 1/n))  
seMuHat
ciMean <- c(muhat - qt(.975, n-2)*seMuHat, muhat + qt(.975, n-2)*seMuHat)
ciMean
```


#### Using `predict()`

In addition to computing the point estimate $\hat{\mu}_{y|x_0}$, the `predict()` command can automatically compute a confidence interval. To do this, set the `interval="confidence"` argument.

```{example}
For the point estimates in Example \@ref(exm:peng-lm-multimean), find a 99\% confidence interval.
```

```{r}
predict(penguin_lm,
        newdata=preddata2,
        interval="confidence", 
        level=0.99)
```

### Plotting CI for Mean Response in R 

### "By hand"
To plot pointwise confidence intervals for $\mu_{y|x_0}$, the first step is compute the intervals for a sequence of predictor variable values. Then add the points to a plot using the `geom_ribbon()` function from `ggplot2`. Because of the quadratic term in Equation \@ref(eq:varslrmean), the interval band has a curved shape.


```{example} 
(Continuation of Example \@ref(exm:penguin-lm-prediction) For the penguin model, plot the pointwise 95% confidence interval for the mean.
```

```{r}
flipper_length_seq <- seq(170, 240, length=200)
mean_conf_int <- predict(penguin_lm,
                         newdata=data.frame(flipper_length_mm=flipper_length_seq),
                         interval="confidence")
mean_conf_int <- as.data.frame(mean_conf_int)
```

```{r echo=F}
g_penguin <- ggplot() + theme_bw() + 
  geom_point(aes(x=flipper_length_mm,
                 y=body_mass_g),
             data=penguins) + 
    xlab("Flipper Length (mm)") +
    ylab("Body Mass (g)")
```

```{r}
g_penguin +
    geom_ribbon(aes(x=flipper_length_seq, ymax=upr, ymin=lwr), 
                data=mean_conf_int,
                fill="grey80") + 
  geom_abline(aes(slope=coef(penguin_lm)[2],
                  intercept=coef(penguin_lm)[1]), col="blue")
```


### Using `geom_smooth()`

Alternatively, we can let `geom_smooth()` do the calculation for us:

```{r echo=TRUE, warning=F, message=F}
g_penguin + 
    geom_smooth(aes(x=flipper_length_mm,
                    y=body_mass_g),
                data=penguins,
                method="lm",
                se=TRUE,
                level=0.99)
```

## Prediction Intervals

Predicting the value of a new observation with $x=x_0$:

 $$\hat y_0 = \hat\beta_0 + \hat\beta_1x_0$$


Difference between true new observation and prediction is:

$$Y_0 - \hat y_0 = (\beta_0 + \beta_1 x_0) - (\hat\beta_0 + \hat\beta_1x_0) + \epsilon_0$$


Uncertainty needs to account for two parts: estimating the mean $(\hat\beta_0 + \hat\beta_1x_0)$ and random error in new observation ($\epsilon_0$)
\begin{align*}
\Var(Y_0 - \hat y_0) &= \Var\left((\beta_0 + \beta_1 x_0) - (\hat\beta_0 + \hat\beta_1x_0)\right) + \Var(\epsilon_0) \\
&= \sigma^2\left(\frac{1}{n}  + \frac{(x_0 - \overline{x})^2}{S_{xx}}\right) + \sigma^2 = \sigma^2\left(\frac{1}{n}  + \frac{(x_0 - \overline{x})^2}{S_{xx}} + 1\right) 
\end{align*}

A $(1-\alpha)100\%$ **prediction interval** for a new observation with $x=x_0$ is:

\begin{align*}
&\Big(\hat y_0 - t_{\alpha/2}\sqrt{\sigma^2\left(1 + \frac{1}{n}  + \frac{(x_0 - \overline{x})^2}{S_{xx}}\right)},\\
& \qquad  \qquad \hat y_0 + t_{\alpha/2}\sqrt{\sigma^2\left(1 + \frac{1}{n}  + \frac{(x_0 - \overline{x})^2}{S_{xx}}\right)} \Big)
\end{align*}


A **prediction interval** is a random interval that, when the model is correct, has a $(1-\alpha)$ probability of containing a new observation that has $x_0$ as its predictor value.



### PI for New Observation in R

```{r eval=FALSE, echo=TRUE, size="footnotesize"}
sePred <- sqrt(seMuHat^2 + summary(penguin_lm)$sigma^2)
yhat_PI <- c(yhat - qt(.975, n-2)*sePred, yhat + qt(.975, n-2)*sePred)
yhat_PI

# Prediction Interval for the mean response
predict(rockies_lm, 
        newdata=data.frame(launch_speed=90),
        interval="prediction", level=0.95)
```


### Plotting PI for New Observation in R


```{r eval=FALSE, echo=TRUE, size="footnotesize"}
yhat_pred_int <- predict(rockies_lm,
                         newdata=data.frame(launch_speed=launch_speed_seq),
                         interval="prediction")
yhat_pred_int <- as.data.frame(yhat_pred_int)

g_rockies_wPI <- g_rockies + 
    geom_ribbon(aes(x=launch_speed_seq, ymax=upr, ymin=lwr), 
                data=yhat_pred_int,
                fill="grey80") + 
  geom_abline(aes(slope=coef(rockies_lm)[2],
                  intercept=coef(rockies_lm)[1]), col="blue") +
  geom_point(aes(x=launch_speed, y=hit_distance_sc), data=rockies)
```

### Plotting CI for Mean Response in R "by hand"

```{r eval=FALSE, echo=TRUE, size="footnotesize"}
g_rockies_wPI
```

### PI vs. CI in R

```{r eval=FALSE, echo=TRUE, size="footnotesize"}
predict(rockies_lm, 
        newdata=data.frame(launch_speed=c(70, 90, 100)),
        interval="confidence", level=0.95)

predict(rockies_lm, 
        newdata=data.frame(launch_speed=c(70, 90, 100)),
        interval="prediction", level=0.95)
```
