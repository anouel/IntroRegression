# Confidence Intervals in SLR {#slrCI}

<!--- For HTML Only --->
`r if (!knitr:::is_latex_output()) '
$\\newcommand{\\E}{\\mathrm{E}}$
$\\newcommand{\\Var}{\\mathrm{Var}}$
'`

```{r include=FALSE}
library(tidyverse)
library(palmerpenguins)
library(broom)
```

## Confidence Intervals (CIs)

### Definition and Interpreation

Hypothesis tests provide an answer to a specific question (*Is there evidence to reject the null hypothesis?*), but they don't directly provide information about the uncertainty in the point estimates.
In many contexts, what is often more useful than a conclusion from a hypothesis test is an estimate of a parameter and its uncertainty. **Confidence intervals** provide a way to describe the uncertainty in a parameter estimate.


```{definition}
A **$(1- \alpha)100\%$ confidence interval** is a random interval that, if the model is correct, would include ("cover") the true value of the parameter with probability $(1 - \alpha)$.

```


In this definition, it is important to note that the *interval* is random, not the parameter. The parameter is a fixed, but unknown, constant, and so it cannot have a probability distribution associated with it.^[Unless one adopts a Bayesian paradigm.] A common *incorrect* interpretation of a CI is that the probability of the parameter being in the interval is $(1- \alpha)100\%$.  

For a single dataset, there is no guarantee that the true value of a parameter will be included within the confidence interval. But if the model is correct, then an interval generated by the same procedure should include the true value in $(1-\alpha)100\%$ of analysis of independently-collected data.  Figure \@ref(fig:plot-sim-coverage) shows the coverage of 95% CIs calculated for 100 simulated datasets when the true value of $\beta_1 = 2$.

```{r plot-sim-coverage, echo=FALSE, fig.cap="Example of coverage of 95% CIs in 100 simulated datasets."}
set.seed(1976)
##############################
# CI coverage via simulation
##############################
numReps <- 100
# Store CI's as matrix since there are two
# values for each replication (lower and upper bound)
ciStore <- matrix(0, nrow = numReps, ncol = 2)

n <- 30
x <- runif(n=n, min=-1, max=1)
beta0 <- 4
beta1 <- 2 
sigma2 <- 2

# Simulate data and fit model, `numReps` times
for(i in 1:numReps) {
    epsilon <- rnorm(n, mean = 0, sd = sqrt(sigma2))
    y <- beta0 + beta1*x + epsilon
    lmfit <- lm(y ~ x)
    ci <- confint(lmfit, level = .95)["x",]
    ciStore[i,] <- ci
}
# Combine into data frame
ci_df <- data.frame(simulation=1:numReps,
                    CIlower=ciStore[,1],
                    CIupper=ciStore[,2]) %>%
  mutate(inCI=ifelse(CIlower<=beta1 & CIupper>=beta1, TRUE, FALSE))
# Plot the CI's
ggplot(ci_df) + theme_bw() +  
  geom_hline(aes(yintercept=2), col="blue", lwd=1.2) + geom_linerange(aes(x=simulation, ymin=CIlower, ymax=CIupper, col=inCI)) +
  scale_color_manual(name="Covers Truth", breaks=c(TRUE, FALSE), values=c("black", "red")) +
  xlab("Simulation Number")
```
<!-- * Ex: Is there an association between latitude and mortality rates? -->
<!-- * Ex: Is the estimated slope more than 1 (\$s per person/km$^2$) in a SLR model with rental prices as outcome and population density the predictor? -->


### Inverting a Hypothesis Test

To create a confidence interval, we *invert* a hypothesis test. 
Recall that for testing the null hypothesis $H_0: \beta_1 = \beta_{10}$ against the alternative hypothesis $H_A: \beta_1 \ne \beta_{10}$, we computed the test statistic
$$t = \frac{\hat\beta_1 - \beta_{10}}{\widehat{se}(\hat\beta_1)}$$
by plugging in $\hat\beta_1$, $\widehat{se}(\hat\beta_1)$, and $\beta_{10}$. We then compared the value of $t$ to a $T_{n-2}$ distribution to compute the $p$-value $p=P(T > |t|)$. 
For a confidence interval, we reverse this process. That is, we plug in $\hat\beta_1$, $\widehat{se}(\hat\beta_1)$, and $t$, then solve for $\beta_{10}$ as an unknown value.

The distribution of  $t = \dfrac{\hat\beta_1 - \beta_{1}}{\widehat{se}(\hat\beta_1)}$ is $T_{n-2}$. This distribution has mean zero and a standardized variance (it's close to 1, although not exactly 1). 
There exists a number, which we denote $t_{\alpha/2}$, such that the area under the curve between $-t_{\alpha/2}$ and $t_{\alpha/2}$ is $1-\alpha$. Mathematically, this can be written:

\begin{equation}
P\left(-t_{\alpha/2} \le \dfrac{\hat\beta_1 - \beta_1}{\widehat{se}(\hat\beta_1)} \le t_{\alpha/2}\right) = 1 - \alpha
(\#eq:ciinvert)
\end{equation}

Graphically, this looks like:

```{r echo=FALSE}
x <- seq(-5, 5, length=100)
tdf <- data.frame(x=x, tdens=dt(x, df=10))
ggt <- ggplot() + theme_classic() + coord_cartesian(xlim=c(-3.2, 3.2), ylim=c(0, 0.5), expand=F) + 
  theme(axis.line.y = element_blank()) + 
  xlab(expression(T[n-2])) + 
  ylab("") + scale_y_continuous(breaks=NULL)+
  geom_hline(aes(yintercept=0)) + 
  geom_line(aes(x=x,y=tdens),
            data=tdf)
ggt + 
  geom_polygon(aes(x=c(-1.5, -1.5, x[x>-1.5 & x < 1.5],1.5, 1.5),
                   y=c(0, dt(-1.5, df=10), dt(x[x>-1.5 & x < 1.5], df=10),  dt(1.5, df=10), 0)),
               fill="grey80") +
  scale_x_continuous(breaks=c(-1.5, 1.5), labels=c("-t", "t"))+ 
  geom_segment(aes(x=1.5, xend=1.5, y=0, yend=dt(1.5, df=10)), col="red") +
    geom_segment(aes(x=-1.5, xend=-1.5, y=0, yend=dt(-1.5, df=10)), col="red")
```



We can rearrange equation \@ref(eq:ciinvert), so that $\beta_1$ is alone in the middle: 

```{asis echo=!FALSE}
\begin{align*}
1-\alpha &= P\left(-t_{\alpha/2}\widehat{se}(\hat\beta_1) \le \hat\beta_1 - \beta_1 \le t_{\alpha/2}\widehat{se}(\hat\beta_1)\right)\\
&= P\left(t_{\alpha/2}\widehat{se}(\hat\beta_1) \ge \beta_1 - \hat\beta_1 \ge -t_{\alpha/2}\widehat{se}(\hat\beta_1)\right)\\
&= P\left(\hat\beta_1 + t_{\alpha/2}\widehat{se}(\hat\beta_1) \ge \beta_1  \ge \hat\beta_1 -t_{\alpha/2}\widehat{se}(\hat\beta_1)\right)\\
&= P\left(\hat\beta_1 - t_{\alpha/2}\widehat{se}(\hat\beta_1) \le \beta_1  \le \hat\beta_1 + t_{\alpha/2}\widehat{se}(\hat\beta_1)\right)\\
\end{align*}
```



## CIs for $\beta_0$ and $\beta_1$
 
The procedure from the previous section  gives a $(1 -\alpha)100\%$ confidence interval for $\beta_1$:
$$\left(\hat\beta_1 - t_{\alpha/2}\widehat{se}(\hat\beta_1), \hat\beta_1 + t_{\alpha/2}\widehat{se}(\hat\beta_1)\right)$$
We can construct a CI for $\beta_0$ in the same way:
$$\left(\hat\beta_0 - t_{\alpha/2}\widehat{se}(\hat\beta_0), \hat\beta_0 + t_{\alpha/2}\widehat{se}(\hat\beta_0)\right)$$




### Confidence Intervals "by hand" in R

To compute a confidence interval "by hand" in R, we can plug in the appropriate values into the formulas.  The estimates $\hat\beta_1$ and $\widehat{se}(\hat\beta_1)$ can be calculated from an `lm` object. 
To compute $t_{\alpha/2}$, use the `qt()` command, which can be used to find $x$ such that $P(T < x) = \tilde{p}$ for a given value of $\tilde{p}$. 
In order to compute $t_{\alpha/2}$, we need to find $x$ such that $P(T < x) = 1- \alpha/2$. 
Because of the symmetry of the $T$ distribution, this will yield an $x = t_{\alpha/2}$. 
This can be implemented in the following code:

```{r}
alpha <- 0.05
t_alphaOver2 <- qt(1-alpha/2,
                   df = 100-2)
t_alphaOver2
```

An alternative approach is to find $P(T > x ) = \alpha/2$. To do this using `qt()`, set the `lower=FALSE` option:
```{r}
t_alphaOver2 <- qt(alpha/2,
                   df = 100-2,
                   lower=FALSE)
t_alphaOver2
```


```{example}
In the penguin data, suppose we wish to construct a confidence interval for $\beta_1$ using the formulas. This can be done with the following code:
```

```{r echo=TRUE}
penguin_lm <- lm(body_mass_g~flipper_length_mm,
                data=penguins)
alpha <- 0.05
t_alphaOver2 <- qt(1-alpha/2,
                   df = nobs(penguin_lm)-2)
CI95Lower <- coef(penguin_lm)[2] - t_alphaOver2 * tidy(penguin_lm)$std.error[2]
CI95Upper <- coef(penguin_lm)[2] + t_alphaOver2 * tidy(penguin_lm)$std.error[2]
c(CI95Lower, CI95Upper)
```


```{example peng-lm-intro-ci}
We can now expand our summary statement from Example \@ref(exm:peng-lm-intro-testingconclusion) about $\beta_1$ to be:
```

*A difference of one mm in flipper length is  associated with an estimated difference of 49.7 g (95% CI: 46.7, 52.7) greater average body mass among penguins in Antarctica. We reject the null hypothesis that there is no linear relationship between flipper length and average penguin body mass ($p < 0.0001$).* 








### Confidence Intervals in R


In practice, it is much simpler to let R compute the confidence interval for you. Two standard options for this are:

* Add `conf.int=TRUE` when calling `tidy()` on the `lm` output. This will add a `conf.low` and `conf.high` column to the tidy output. By default, a 95% confidence interval is constructed. To change the level, set `conf.level=` to a different value.
* Call the `confint()` command directly on the `lm` object. This prints the confidence intervals only (no point estimates). To change the level, set the `level=` argument.

```{r eval=TRUE, echo=TRUE}
tidy(penguin_lm, conf.int=TRUE)
tidy(penguin_lm, conf.int=TRUE, conf.level=0.99)
```


```{r}
confint(penguin_lm)
```



## CIs for $\sigma^2$


Confidence intervals for $\sigma^2$ are created using the same strategy. It can be shown that $\dfrac{SS_{res}}{\sigma^2}  = \dfrac{(n-2)\hat\sigma^2}{\sigma^2} \sim \chi^2_{n-2}$


```{r echo=FALSE, fig.width=5, fig.height=4,  fig.align="c"}
x <- seq(0, 10, length=100)
chidf <- data.frame(x=x, chidens=dchisq(x, df=4))
ggchi2 <- ggplot() + theme_classic() + coord_cartesian(xlim=c(0, 10), expand=F) + 
  theme(axis.line.y = element_blank()) + 
  xlab(expression(chi[n-2]^2)) + ylab("") + scale_y_continuous(breaks=NULL) +
  geom_hline(aes(yintercept=0)) + 
  geom_line(aes(x=x,y=chidens),
            data=chidf) +
  geom_polygon(aes(x=c(1, x[x>1 & x < 8], 8),
                   y=c(0, chidf$chidens[x>1 &  x < 8], 0)),
               fill="grey80")
ggchi2 + scale_x_continuous(breaks=c(1, 8), labels=c(expression(chi[1-alpha/2,n-2]^2), expression(chi[alpha/2, n-2]^2)))
```

$$P\left(\chi^2_{1-\frac{\alpha}{2}, n-2} \le \frac{(n-2)\hat\sigma^2}{\sigma^2} \le \chi^2_{\frac{\alpha}{2}, n-2}\right) = 1 - \alpha$$

\vspace{1cm}


$$P\left(\frac{(n-2)\hat\sigma^2}{\chi^2_{\frac{\alpha}{2}, n-2}} \le \sigma^2 \le \frac{(n-2)\hat\sigma^2}{\chi^2_{1-\frac{\alpha}{2}, n-2}}\right) = 1 - \alpha$$



## Confidence Interval for the Mean Response

### Inference for the Mean Response

Confidence interval for the mean response:

$$\left(\hat\mu_{y|x_0} - t_{\alpha/2}\widehat{se}(\hat\mu_{y|x_0}), \hat\mu_{y|x_0} + t_{\alpha/2}\widehat{se}(\hat\mu_{y|x_0})\right)$$

Hypothesis testing the mean response:

$$H_0: \mu_{y|x_0} = \mu^0_{y|x_0} \qquad \text{vs.} \qquad H_A: \mu_{y|x_0} \ne \mu^0_{y|x_0}$$

$$t = \frac{\hat\mu_{y|x_0} - \mu^0_{y|x_0}}{\widehat{se}(\hat\mu_{y|x_0})}$$

Both require $\widehat{se}(\hat\mu_{y|x_0})$

### Variance of $\hat\mu_{y|x_0}$

\begin{align*}
\Var(\hat\mu_{y|x_0}) &= \Var\left(\hat\beta_0 + \hat\beta_1 x_0 \right)  \textcolor{red}{\ne \Var(\hat\beta_0) + \Var(\hat\beta_1x_0)} \\
& = \Var\left(\overline{y} - \hat\beta_1\overline{x} + \hat\beta_1 x_0 \right)\\
& = \Var\left(\overline{y} + \hat\beta_1(x_0 - \overline{x} )\right)\\
& = \Var\left(\overline{y}\right)  + \Var\left(\hat\beta_1(x_0 - \overline{x}) \right)\\
& = \frac{\sigma^2}{n} + (x_0 - \overline{x})^2\Var\left(\hat\beta_1\right)\\
& =  \frac{\sigma^2}{n}  + (x_0 - \overline{x})^2\frac{\sigma^2}{S_{xx}}\\
& =  \sigma^2\left(\frac{1}{n}  + \frac{(x_0 - \overline{x})^2}{S_{xx}}\right)
\end{align*}

Note: This is smallest when $x_0 = \overline{x}$

### Confidence Interval for $\mu_{y|x_0}$

```{r eval=FALSE}
g_rockies + geom_smooth(aes(x=launch_speed,
                   y=hit_distance_sc), method="lm", se=TRUE)
```


### Confidence Interval for $\mu_{y|x_0}$

```{r eval=FALSE, include=FALSE}
hurr <- read_csv("../../Data/hurricanes.csv")
hurr <- subset(hurr, !is.na(mean_precip))
```


```{r eval=FALSE}
g_hurr <- ggplot(hurr) + 
  theme_bw() + 
     geom_point(aes(y= mean_precip,
                    x=windmax)) +
  geom_smooth(aes(y= mean_precip,
                    x=windmax), method="lm") + 
     xlab("Maximum Wind Speed (knots)") +
     ylab("Mean Precipitation (mm) within 200 km") +
  ggtitle("Hurricanes (1988-2015)") 
g_hurr
```




## Exercises

(To be added)
